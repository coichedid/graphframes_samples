 WARN [2019-11-26 10:49:44,080] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2019-11-26 10:49:44,463] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2019-11-26 10:49:44,495] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.18.0.6:45151
 INFO [2019-11-26 10:49:44,499] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 45151
 INFO [2019-11-26 10:49:44,501] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 45151
 INFO [2019-11-26 10:49:45,508] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.18.0.6, callbackPort: 36151, callbackInfo: CallbackInfo(host:172.18.0.6, port:45151)
 INFO [2019-11-26 10:49:45,685] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2019-11-26 10:49:45,691] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2019-11-26 10:49:45,715] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2019-11-26 10:49:45,723] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2019-11-26 10:49:45,730] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2019-11-26 10:49:45,737] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2019-11-26 10:49:45,876] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2019-11-26 10:49:45,919] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2019-11-26 10:49:45,923] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8090
 INFO [2019-11-26 10:49:45,924] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2019-11-26 10:49:45,927] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2019-11-26 10:49:45,928] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2019-11-26 10:49:45,932] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_670010753
 INFO [2019-11-26 10:49:46,609] ({pool-2-thread-2} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:49:46,616] ({pool-2-thread-2} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2019-11-26 10:49:55,379] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.4.4
 INFO [2019-11-26 10:49:55,430] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2019-11-26 10:49:55,522] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2019-11-26 10:49:55,524] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2019-11-26 10:49:55,526] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2019-11-26 10:49:55,527] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2019-11-26 10:49:55,528] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2019-11-26 10:49:55,916] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 34751.
 INFO [2019-11-26 10:49:55,961] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2019-11-26 10:49:55,994] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2019-11-26 10:49:56,004] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2019-11-26 10:49:56,005] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2019-11-26 10:49:56,022] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-7583a033-158a-42d1-bfd0-7332c4dea928
 INFO [2019-11-26 10:49:56,042] ({pool-2-thread-2} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2019-11-26 10:49:56,072] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2019-11-26 10:49:56,240] ({pool-2-thread-2} Log.java[initialized]:192) - Logging initialized @13913ms
 INFO [2019-11-26 10:49:56,353] ({pool-2-thread-2} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2019-11-26 10:49:56,386] ({pool-2-thread-2} Server.java[doStart]:419) - Started @14059ms
 INFO [2019-11-26 10:49:56,426] ({pool-2-thread-2} AbstractConnector.java[doStart]:278) - Started ServerConnector@1cf5de81{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:49:56,428] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2019-11-26 10:49:56,485] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5bd45f6a{/jobs,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,489] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@c9b8e52{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,493] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@74cf8488{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,497] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@15da7501{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,502] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@456380f6{/stages,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,504] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4d00a716{/stages/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,506] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6384d78f{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,509] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@34fda463{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,512] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@718035dc{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,519] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@523763a3{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,522] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@420d4f8a{/storage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,523] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1b0a3514{/storage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,525] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6b54cd7c{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,526] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@29791ce{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,528] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2a4eef09{/environment,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,535] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@60a6ddc1{/environment/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,537] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2d54c384{/executors,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,540] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@13732e01{/executors/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,543] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4e18adc1{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,545] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@18062916{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,562] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@13459171{/static,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,568] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@41c6ae1c{/,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,572] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@363a3dc9{/api,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,574] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@465a8c17{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,575] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7fdbfd48{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:56,577] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://b77469278276:4040
 INFO [2019-11-26 10:49:56,627] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://b77469278276:34751/jars/spark-interpreter-0.8.1.jar with timestamp 1574765396626
 WARN [2019-11-26 10:49:56,629] ({pool-2-thread-2} Logging.scala[logWarning]:66) - The jar /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar has been added already. Overwriting of added jars is not supported in the current version.
 INFO [2019-11-26 10:49:57,353] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2019-11-26 10:49:57,446] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.18.0.2:7077 after 54 ms (0 ms spent in bootstraps)
 INFO [2019-11-26 10:49:57,596] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20191126104957-0006
 INFO [2019-11-26 10:49:57,609] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37313.
 INFO [2019-11-26 10:49:57,610] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Server created on b77469278276:37313
 INFO [2019-11-26 10:49:57,613] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2019-11-26 10:49:57,659] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, b77469278276, 37313, None)
 INFO [2019-11-26 10:49:57,670] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager b77469278276:37313 with 366.3 MB RAM, BlockManagerId(driver, b77469278276, 37313, None)
 INFO [2019-11-26 10:49:57,675] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, b77469278276, 37313, None)
 INFO [2019-11-26 10:49:57,677] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, b77469278276, 37313, None)
 INFO [2019-11-26 10:49:57,955] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@3bb2f328{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:49:57,980] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2019-11-26 10:50:07,764] ({pool-2-thread-2} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2019-11-26 10:50:08,334] ({pool-2-thread-2} IPythonInterpreter.java[setAdditionalPythonPath]:103) - setAdditionalPythonPath: /opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python
 INFO [2019-11-26 10:50:08,337] ({pool-2-thread-2} IPythonInterpreter.java[open]:135) - Python Exec: python
 INFO [2019-11-26 10:50:08,769] ({pool-2-thread-2} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:50:08,772] ({pool-2-thread-2} IPythonInterpreter.java[open]:146) - Launching IPython Kernel at port: 33569
 INFO [2019-11-26 10:50:08,773] ({pool-2-thread-2} IPythonInterpreter.java[open]:147) - Launching JVM Gateway at port: 45491
 INFO [2019-11-26 10:50:08,975] ({pool-2-thread-2} IPythonInterpreter.java[setupIPythonEnv]:319) - PYTHONPATH:/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python:/opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/:
 INFO [2019-11-26 10:50:09,388] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:09,489] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:09,590] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:09,692] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:09,794] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:09,896] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,001] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,103] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,205] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,411] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,535] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,641] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,751] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:50:10,875] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:290) - IPython Kernel is Running
 INFO [2019-11-26 10:50:10,876] ({pool-2-thread-2} Py4JUtils.java[createGatewayServer]:44) - Launching GatewayServer at 127.0.0.1:45491
 INFO [2019-11-26 10:50:11,974] ({pool-2-thread-2} PySparkInterpreter.java[open]:130) - IPython is available, Use IPySparkInterpreter to replace PySparkInterpreter
 INFO [2019-11-26 10:50:12,131] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_670010753
ERROR [2019-11-26 10:50:41,821] ({grpc-default-executor-0} SerializingExecutor.java[run]:120) - Exception while executing runnable io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@6b9e1cfc
java.lang.NullPointerException
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)
	at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:50:41,845] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
 INFO [2019-11-26 10:50:41,855] ({pool-1-thread-1} AbstractConnector.java[doStop]:318) - Stopped Spark@1cf5de81{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:50:41,867] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://b77469278276:4040
 INFO [2019-11-26 10:50:41,883] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Shutting down all executors
 INFO [2019-11-26 10:50:41,894] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Asking each executor to shut down
 INFO [2019-11-26 10:50:41,946] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2019-11-26 10:50:41,967] ({pool-1-thread-1} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2019-11-26 10:50:41,968] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2019-11-26 10:50:41,980] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2019-11-26 10:50:41,984] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2019-11-26 10:50:42,003] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2019-11-26 10:50:42,007] ({pool-1-thread-1} Logging.scala[logInfo]:54) - SparkContext already stopped.
 INFO [2019-11-26 10:50:42,033] ({pool-1-thread-1} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
 INFO [2019-11-26 10:50:42,034] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
 WARN [2019-11-26 10:50:42,660] ({Exec Default Executor} IPythonInterpreter.java[onProcessFailed]:398) - Exception happens in Python Process
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:50:44,149] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2019-11-26 10:50:44,151] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-db58bdcf-9363-4fe1-a314-784b05a097ea/pyspark-f005defa-c761-4dc9-bf69-04231249471d
 INFO [2019-11-26 10:50:44,165] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-db58bdcf-9363-4fe1-a314-784b05a097ea
 INFO [2019-11-26 10:50:44,169] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-07e08f27-d3be-4520-a930-c8395007f2c4
 WARN [2019-11-26 10:50:57,643] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2019-11-26 10:50:58,093] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2019-11-26 10:50:58,125] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.18.0.6:44575
 INFO [2019-11-26 10:50:58,129] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 44575
 INFO [2019-11-26 10:50:58,144] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 44575
 INFO [2019-11-26 10:50:59,151] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.18.0.6, callbackPort: 34469, callbackInfo: CallbackInfo(host:172.18.0.6, port:44575)
 INFO [2019-11-26 10:50:59,271] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2019-11-26 10:50:59,276] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2019-11-26 10:50:59,298] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2019-11-26 10:50:59,307] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2019-11-26 10:50:59,312] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2019-11-26 10:50:59,315] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2019-11-26 10:50:59,420] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2019-11-26 10:50:59,450] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2019-11-26 10:50:59,452] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:131) - Server Port: 8090
 INFO [2019-11-26 10:50:59,452] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2019-11-26 10:50:59,456] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2019-11-26 10:50:59,457] ({pool-1-thread-3} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2019-11-26 10:50:59,468] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_710998675
 INFO [2019-11-26 10:50:59,942] ({pool-2-thread-3} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:50:59,950] ({pool-2-thread-3} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2019-11-26 10:51:10,156] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Running Spark version 2.4.4
 INFO [2019-11-26 10:51:10,209] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2019-11-26 10:51:10,306] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2019-11-26 10:51:10,307] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2019-11-26 10:51:10,307] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2019-11-26 10:51:10,308] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2019-11-26 10:51:10,309] ({pool-2-thread-3} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2019-11-26 10:51:10,720] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 37055.
 INFO [2019-11-26 10:51:10,759] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2019-11-26 10:51:10,805] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2019-11-26 10:51:10,809] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2019-11-26 10:51:10,811] ({pool-2-thread-3} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2019-11-26 10:51:10,827] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-41cf226d-cb66-45ad-9872-6ca2a1bf7d0d
 INFO [2019-11-26 10:51:10,863] ({pool-2-thread-3} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2019-11-26 10:51:10,894] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2019-11-26 10:51:11,026] ({pool-2-thread-3} Log.java[initialized]:192) - Logging initialized @14937ms
 INFO [2019-11-26 10:51:11,584] ({pool-2-thread-3} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2019-11-26 10:51:11,615] ({pool-2-thread-3} Server.java[doStart]:419) - Started @15526ms
 INFO [2019-11-26 10:51:11,654] ({pool-2-thread-3} AbstractConnector.java[doStart]:278) - Started ServerConnector@267041af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:51:11,655] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2019-11-26 10:51:11,724] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2f387b7{/jobs,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,725] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1d749b76{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,727] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@76660f32{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,729] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@286317e5{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,731] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@117596b4{/stages,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,735] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@572c0437{/stages/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,737] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@419fdeaf{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,739] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7b3465f0{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,741] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4461a69f{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,742] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2c50e240{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,744] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@160b9bbd{/storage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,745] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4ec87769{/storage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,747] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7d47571{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,752] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2c3dd529{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,755] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@66216560{/environment,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,757] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6b5f25f2{/environment/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,759] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4f84aa15{/executors,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,761] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@d52ba51{/executors/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,763] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6035c4fe{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,768] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@72d71dbf{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,781] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@18e9c5f2{/static,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,789] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@32318905{/,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,792] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2f425559{/api,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,793] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5f21bf3d{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,795] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4e8851{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:11,803] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://b77469278276:4040
 INFO [2019-11-26 10:51:11,841] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://b77469278276:37055/jars/spark-interpreter-0.8.1.jar with timestamp 1574765471841
 WARN [2019-11-26 10:51:11,843] ({pool-2-thread-3} Logging.scala[logWarning]:66) - The jar /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar has been added already. Overwriting of added jars is not supported in the current version.
 INFO [2019-11-26 10:51:12,054] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2019-11-26 10:51:12,157] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.18.0.2:7077 after 53 ms (0 ms spent in bootstraps)
 INFO [2019-11-26 10:51:12,313] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20191126105112-0007
 INFO [2019-11-26 10:51:12,327] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45761.
 INFO [2019-11-26 10:51:12,328] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Server created on b77469278276:45761
 INFO [2019-11-26 10:51:12,331] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2019-11-26 10:51:12,368] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, b77469278276, 45761, None)
 INFO [2019-11-26 10:51:12,374] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager b77469278276:45761 with 366.3 MB RAM, BlockManagerId(driver, b77469278276, 45761, None)
 INFO [2019-11-26 10:51:12,378] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, b77469278276, 45761, None)
 INFO [2019-11-26 10:51:12,380] ({pool-2-thread-3} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, b77469278276, 45761, None)
 INFO [2019-11-26 10:51:12,594] ({pool-2-thread-3} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@12eab2f7{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:51:12,644] ({pool-2-thread-3} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2019-11-26 10:51:19,568] ({pool-2-thread-3} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2019-11-26 10:51:19,964] ({pool-2-thread-3} IPythonInterpreter.java[setAdditionalPythonPath]:103) - setAdditionalPythonPath: /opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python
 INFO [2019-11-26 10:51:19,968] ({pool-2-thread-3} IPythonInterpreter.java[open]:135) - Python Exec: python
 INFO [2019-11-26 10:51:20,397] ({pool-2-thread-3} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:51:20,401] ({pool-2-thread-3} IPythonInterpreter.java[open]:146) - Launching IPython Kernel at port: 36271
 INFO [2019-11-26 10:51:20,404] ({pool-2-thread-3} IPythonInterpreter.java[open]:147) - Launching JVM Gateway at port: 37315
 INFO [2019-11-26 10:51:20,692] ({pool-2-thread-3} IPythonInterpreter.java[setupIPythonEnv]:319) - PYTHONPATH:/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python:/opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/:
 INFO [2019-11-26 10:51:21,221] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,323] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,433] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,535] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,636] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,737] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,841] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:21,946] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:22,169] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:22,277] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:22,387] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:51:22,502] ({pool-2-thread-3} IPythonInterpreter.java[launchIPythonKernel]:290) - IPython Kernel is Running
 INFO [2019-11-26 10:51:22,504] ({pool-2-thread-3} Py4JUtils.java[createGatewayServer]:44) - Launching GatewayServer at 127.0.0.1:37315
 INFO [2019-11-26 10:51:23,763] ({pool-2-thread-3} PySparkInterpreter.java[open]:130) - IPython is available, Use IPySparkInterpreter to replace PySparkInterpreter
 INFO [2019-11-26 10:51:23,898] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_710998675
 INFO [2019-11-26 10:51:28,337] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_710998675
 INFO [2019-11-26 10:51:28,622] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_710998675
 INFO [2019-11-26 10:52:18,309] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
ERROR [2019-11-26 10:52:18,316] ({grpc-default-executor-0} SerializingExecutor.java[run]:120) - Exception while executing runnable io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@72d740fd
java.lang.NullPointerException
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)
	at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:52:18,324] ({pool-1-thread-1} AbstractConnector.java[doStop]:318) - Stopped Spark@267041af{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 WARN [2019-11-26 10:52:18,336] ({Exec Default Executor} IPythonInterpreter.java[onProcessFailed]:398) - Exception happens in Python Process
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:52:18,339] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://b77469278276:4040
 INFO [2019-11-26 10:52:18,346] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Shutting down all executors
 INFO [2019-11-26 10:52:18,351] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Asking each executor to shut down
 INFO [2019-11-26 10:52:18,394] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2019-11-26 10:52:18,408] ({pool-1-thread-1} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2019-11-26 10:52:18,410] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2019-11-26 10:52:18,416] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2019-11-26 10:52:18,419] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2019-11-26 10:52:18,428] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2019-11-26 10:52:18,430] ({pool-1-thread-1} Logging.scala[logInfo]:54) - SparkContext already stopped.
 INFO [2019-11-26 10:52:18,439] ({pool-1-thread-1} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
 INFO [2019-11-26 10:52:18,439] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
 INFO [2019-11-26 10:52:20,555] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2019-11-26 10:52:20,558] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-b22dd9f2-a234-4812-b186-8f851617eb14
 INFO [2019-11-26 10:52:20,563] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-e1de6da4-7457-497a-94e1-364183818c04
 INFO [2019-11-26 10:52:20,567] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-e1de6da4-7457-497a-94e1-364183818c04/pyspark-21911eaf-57cb-456b-a710-c4129d5cae46
 WARN [2019-11-26 10:52:29,394] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2019-11-26 10:52:29,729] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2019-11-26 10:52:29,795] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.18.0.6:39671
 INFO [2019-11-26 10:52:29,802] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 39671
 INFO [2019-11-26 10:52:29,805] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 39671
 INFO [2019-11-26 10:52:30,815] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.18.0.6, callbackPort: 46535, callbackInfo: CallbackInfo(host:172.18.0.6, port:39671)
 INFO [2019-11-26 10:52:31,032] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2019-11-26 10:52:31,041] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2019-11-26 10:52:31,053] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2019-11-26 10:52:31,062] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2019-11-26 10:52:31,077] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2019-11-26 10:52:31,089] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2019-11-26 10:52:31,290] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2019-11-26 10:52:31,336] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2019-11-26 10:52:31,339] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8090
 INFO [2019-11-26 10:52:31,341] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2019-11-26 10:52:31,353] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2019-11-26 10:52:31,355] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2019-11-26 10:52:31,363] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_991510052
 INFO [2019-11-26 10:52:32,013] ({pool-2-thread-2} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:52:32,022] ({pool-2-thread-2} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2019-11-26 10:52:41,071] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.4.4
 INFO [2019-11-26 10:52:41,146] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2019-11-26 10:52:41,277] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2019-11-26 10:52:41,278] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2019-11-26 10:52:41,278] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2019-11-26 10:52:41,279] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2019-11-26 10:52:41,284] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2019-11-26 10:52:41,711] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 44231.
 INFO [2019-11-26 10:52:41,764] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2019-11-26 10:52:41,795] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2019-11-26 10:52:41,805] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2019-11-26 10:52:41,806] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2019-11-26 10:52:41,835] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-32eb07fe-ada4-4370-97d6-d8798e2159d6
 INFO [2019-11-26 10:52:41,858] ({pool-2-thread-2} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2019-11-26 10:52:41,899] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2019-11-26 10:52:42,021] ({pool-2-thread-2} Log.java[initialized]:192) - Logging initialized @14076ms
 INFO [2019-11-26 10:52:42,560] ({pool-2-thread-2} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2019-11-26 10:52:42,588] ({pool-2-thread-2} Server.java[doStart]:419) - Started @14643ms
 INFO [2019-11-26 10:52:42,624] ({pool-2-thread-2} AbstractConnector.java[doStart]:278) - Started ServerConnector@fc68c59{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:52:42,625] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2019-11-26 10:52:42,673] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@50b4de09{/jobs,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,675] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@42adf5ed{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,676] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6d946e9c{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,678] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6f748d5f{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,679] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@425b1fc1{/stages,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,681] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@c757998{/stages/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,690] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4db6da79{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,692] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@3bc21955{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,693] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@405c6946{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,695] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5b634538{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,696] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@27142749{/storage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,697] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@c378a4f{/storage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,700] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2f02d4d6{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,704] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6e090e8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,706] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6821526c{/environment,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,708] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5874d8d5{/environment/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,709] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@61690369{/executors,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,711] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@47b22499{/executors/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,713] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@25e2bc31{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,715] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5b2e7a28{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,727] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7275486f{/static,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,729] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@509eda48{/,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,731] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@63c7deb3{/api,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,735] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@24537cd8{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,738] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@eec4a8f{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:42,741] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://b77469278276:4040
 INFO [2019-11-26 10:52:42,787] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://b77469278276:44231/jars/spark-interpreter-0.8.1.jar with timestamp 1574765562785
 WARN [2019-11-26 10:52:42,789] ({pool-2-thread-2} Logging.scala[logWarning]:66) - The jar /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar has been added already. Overwriting of added jars is not supported in the current version.
 INFO [2019-11-26 10:52:42,992] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2019-11-26 10:52:43,105] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.18.0.2:7077 after 52 ms (0 ms spent in bootstraps)
 INFO [2019-11-26 10:52:43,270] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20191126105243-0008
 INFO [2019-11-26 10:52:43,295] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38859.
 INFO [2019-11-26 10:52:43,296] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Server created on b77469278276:38859
 INFO [2019-11-26 10:52:43,303] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2019-11-26 10:52:43,346] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, b77469278276, 38859, None)
 INFO [2019-11-26 10:52:43,354] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager b77469278276:38859 with 366.3 MB RAM, BlockManagerId(driver, b77469278276, 38859, None)
 INFO [2019-11-26 10:52:43,360] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, b77469278276, 38859, None)
 INFO [2019-11-26 10:52:43,361] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, b77469278276, 38859, None)
 INFO [2019-11-26 10:52:43,594] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6b2f3f0f{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:52:43,659] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2019-11-26 10:52:50,786] ({pool-2-thread-2} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2019-11-26 10:52:51,140] ({pool-2-thread-2} IPythonInterpreter.java[setAdditionalPythonPath]:103) - setAdditionalPythonPath: /opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python
 INFO [2019-11-26 10:52:51,144] ({pool-2-thread-2} IPythonInterpreter.java[open]:135) - Python Exec: python
 INFO [2019-11-26 10:52:51,623] ({pool-2-thread-2} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:52:51,626] ({pool-2-thread-2} IPythonInterpreter.java[open]:146) - Launching IPython Kernel at port: 38259
 INFO [2019-11-26 10:52:51,630] ({pool-2-thread-2} IPythonInterpreter.java[open]:147) - Launching JVM Gateway at port: 46399
 INFO [2019-11-26 10:52:51,842] ({pool-2-thread-2} IPythonInterpreter.java[setupIPythonEnv]:319) - PYTHONPATH:/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python:/opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/:
 INFO [2019-11-26 10:52:52,286] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,387] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,488] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,591] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,693] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,797] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:52,900] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:53,086] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:53,195] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:53,304] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:53,410] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:52:53,524] ({pool-2-thread-2} IPythonInterpreter.java[launchIPythonKernel]:290) - IPython Kernel is Running
 INFO [2019-11-26 10:52:53,525] ({pool-2-thread-2} Py4JUtils.java[createGatewayServer]:44) - Launching GatewayServer at 127.0.0.1:46399
 INFO [2019-11-26 10:52:54,809] ({pool-2-thread-2} PySparkInterpreter.java[open]:130) - IPython is available, Use IPySparkInterpreter to replace PySparkInterpreter
 INFO [2019-11-26 10:52:54,939] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_991510052
 INFO [2019-11-26 10:56:06,416] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20191126-105548_2050929170 started by scheduler interpreter_1051754929
 INFO [2019-11-26 10:56:08,244] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20191126-105548_2050929170 finished by scheduler interpreter_1051754929
 INFO [2019-11-26 10:56:43,873] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
ERROR [2019-11-26 10:56:43,874] ({grpc-default-executor-1} SerializingExecutor.java[run]:120) - Exception while executing runnable io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed@2a16ece9
java.lang.NullPointerException
	at io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:395)
	at io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:426)
	at io.grpc.internal.ClientCallImpl.access$100(ClientCallImpl.java:76)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.close(ClientCallImpl.java:512)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl.access$700(ClientCallImpl.java:429)
	at io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:544)
	at io.grpc.internal.ContextRunnable.run(ContextRunnable.java:52)
	at io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:117)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:56:43,890] ({pool-1-thread-1} AbstractConnector.java[doStop]:318) - Stopped Spark@fc68c59{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:56:43,893] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://b77469278276:4040
 INFO [2019-11-26 10:56:43,906] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Shutting down all executors
 INFO [2019-11-26 10:56:43,910] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Asking each executor to shut down
 INFO [2019-11-26 10:56:43,952] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2019-11-26 10:56:43,969] ({pool-1-thread-1} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2019-11-26 10:56:43,971] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2019-11-26 10:56:43,979] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2019-11-26 10:56:43,984] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2019-11-26 10:56:43,999] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2019-11-26 10:56:44,001] ({pool-1-thread-1} Logging.scala[logInfo]:54) - SparkContext already stopped.
 INFO [2019-11-26 10:56:44,013] ({pool-1-thread-1} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
 INFO [2019-11-26 10:56:44,014] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
 WARN [2019-11-26 10:56:44,586] ({Exec Default Executor} IPythonInterpreter.java[onProcessFailed]:398) - Exception happens in Python Process
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2019-11-26 10:56:46,129] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2019-11-26 10:56:46,133] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-c6458da6-92f9-4e64-afd0-1aa3bb61a6df/pyspark-016c6228-dcb6-4eec-ade7-f220eac064ce
 INFO [2019-11-26 10:56:46,142] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-6d3983af-0c0c-41fe-bad9-578ff996c211
 INFO [2019-11-26 10:56:46,145] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-c6458da6-92f9-4e64-afd0-1aa3bb61a6df
 WARN [2019-11-26 10:57:02,278] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2019-11-26 10:57:02,524] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2019-11-26 10:57:02,559] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.18.0.6:36207
 INFO [2019-11-26 10:57:02,562] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 36207
 INFO [2019-11-26 10:57:02,569] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 36207
 INFO [2019-11-26 10:57:03,578] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.18.0.6, callbackPort: 37223, callbackInfo: CallbackInfo(host:172.18.0.6, port:36207)
 INFO [2019-11-26 10:57:03,711] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2019-11-26 10:57:03,717] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2019-11-26 10:57:03,741] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2019-11-26 10:57:03,754] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2019-11-26 10:57:03,761] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2019-11-26 10:57:03,767] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2019-11-26 10:57:03,952] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2019-11-26 10:57:04,002] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2019-11-26 10:57:04,007] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8090
 INFO [2019-11-26 10:57:04,008] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2019-11-26 10:57:04,017] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2019-11-26 10:57:04,018] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2019-11-26 10:57:04,049] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20191126-105548_2050929170 started by scheduler interpreter_1264113301
 INFO [2019-11-26 10:57:15,279] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20191126-105548_2050929170 finished by scheduler interpreter_1264113301
 INFO [2019-11-26 10:57:49,732] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20191126-105548_2050929170 started by scheduler interpreter_1264113301
 INFO [2019-11-26 10:57:59,753] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20191126-105548_2050929170 finished by scheduler interpreter_1264113301
 INFO [2019-11-26 10:58:07,657] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_640386539
 INFO [2019-11-26 10:58:08,189] ({pool-2-thread-6} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:58:08,195] ({pool-2-thread-6} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2019-11-26 10:58:11,856] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Running Spark version 2.4.4
 INFO [2019-11-26 10:58:11,920] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2019-11-26 10:58:12,059] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2019-11-26 10:58:12,063] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2019-11-26 10:58:12,065] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2019-11-26 10:58:12,067] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2019-11-26 10:58:12,068] ({pool-2-thread-6} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2019-11-26 10:58:12,572] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 41243.
 INFO [2019-11-26 10:58:12,625] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2019-11-26 10:58:12,673] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2019-11-26 10:58:12,683] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2019-11-26 10:58:12,686] ({pool-2-thread-6} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2019-11-26 10:58:12,715] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-ae74c13b-7f5b-47b4-89af-5ecc7aa37213
 INFO [2019-11-26 10:58:12,736] ({pool-2-thread-6} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2019-11-26 10:58:12,765] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2019-11-26 10:58:12,931] ({pool-2-thread-6} Log.java[initialized]:192) - Logging initialized @72195ms
 INFO [2019-11-26 10:58:13,042] ({pool-2-thread-6} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2019-11-26 10:58:13,074] ({pool-2-thread-6} Server.java[doStart]:419) - Started @72338ms
 INFO [2019-11-26 10:58:13,136] ({pool-2-thread-6} AbstractConnector.java[doStart]:278) - Started ServerConnector@69be06a9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:58:13,138] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2019-11-26 10:58:13,189] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4919c53e{/jobs,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,190] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@12568d4a{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,191] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4136be93{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,194] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4a27c79{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,199] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@22389d7a{/stages,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,201] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@560e6d88{/stages/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,203] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@16ab280b{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,208] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@420f1257{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,210] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@d2b916d{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,215] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@62c1428c{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,224] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@47249756{/storage,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,226] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7d03b84f{/storage/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,233] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2cf2ee7b{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,235] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@444f1c4b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,237] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2732adb3{/environment,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,239] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4793b8da{/environment/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,241] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7ca91765{/executors,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,244] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4038f1ff{/executors/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,249] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7255937e{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,253] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@285aa086{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,273] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1c7c88d7{/static,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,276] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@34d52c73{/,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,285] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@390913df{/api,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,287] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@49b098c8{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,289] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4424253d{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:13,296] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://b77469278276:4040
 INFO [2019-11-26 10:58:13,372] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://b77469278276:41243/jars/spark-interpreter-0.8.1.jar with timestamp 1574765893371
 INFO [2019-11-26 10:58:13,374] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Added JAR /zeppelin/local-repo/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar at spark://b77469278276:41243/jars/graphframes-0.7.0-spark2.4-s_2.11.jar with timestamp 1574765893374
 INFO [2019-11-26 10:58:13,375] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Added JAR /zeppelin/local-repo/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar at spark://b77469278276:41243/jars/scala-library-2.11.8.jar with timestamp 1574765893375
 INFO [2019-11-26 10:58:13,376] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Added JAR /zeppelin/local-repo/org/slf4j/slf4j-api/1.7.16/slf4j-api-1.7.16.jar at spark://b77469278276:41243/jars/slf4j-api-1.7.16.jar with timestamp 1574765893376
 WARN [2019-11-26 10:58:13,383] ({pool-2-thread-6} Logging.scala[logWarning]:66) - The jar /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar has been added already. Overwriting of added jars is not supported in the current version.
 INFO [2019-11-26 10:58:13,791] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2019-11-26 10:58:13,935] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.18.0.2:7077 after 95 ms (0 ms spent in bootstraps)
 INFO [2019-11-26 10:58:14,124] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20191126105814-0009
 INFO [2019-11-26 10:58:14,138] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38721.
 INFO [2019-11-26 10:58:14,140] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Server created on b77469278276:38721
 INFO [2019-11-26 10:58:14,143] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2019-11-26 10:58:14,203] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, b77469278276, 38721, None)
 INFO [2019-11-26 10:58:14,211] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Registering block manager b77469278276:38721 with 366.3 MB RAM, BlockManagerId(driver, b77469278276, 38721, None)
 INFO [2019-11-26 10:58:14,222] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, b77469278276, 38721, None)
 INFO [2019-11-26 10:58:14,224] ({pool-2-thread-6} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, b77469278276, 38721, None)
 INFO [2019-11-26 10:58:14,542] ({pool-2-thread-6} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@341e1267{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2019-11-26 10:58:14,588] ({pool-2-thread-6} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2019-11-26 10:58:22,262] ({pool-2-thread-6} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2019-11-26 10:58:23,100] ({pool-2-thread-6} IPythonInterpreter.java[setAdditionalPythonPath]:103) - setAdditionalPythonPath: /opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python
 INFO [2019-11-26 10:58:23,113] ({pool-2-thread-6} IPythonInterpreter.java[open]:135) - Python Exec: python
 INFO [2019-11-26 10:58:23,884] ({pool-2-thread-6} IPythonInterpreter.java[checkIPythonPrerequisite]:198) - IPython prerequisite is met
 INFO [2019-11-26 10:58:23,887] ({pool-2-thread-6} IPythonInterpreter.java[open]:146) - Launching IPython Kernel at port: 45261
 INFO [2019-11-26 10:58:23,888] ({pool-2-thread-6} IPythonInterpreter.java[open]:147) - Launching JVM Gateway at port: 35131
 INFO [2019-11-26 10:58:24,246] ({pool-2-thread-6} IPythonInterpreter.java[setupIPythonEnv]:319) - PYTHONPATH:/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/zeppelin/interpreter/lib/python:/opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/:
 INFO [2019-11-26 10:58:24,782] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:24,887] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:24,989] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,091] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,175] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,278] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,379] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,481] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:297) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,743] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,855] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:25,972] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,085] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,194] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,305] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,417] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,527] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:293) - Wait for IPython Kernel to be started
 INFO [2019-11-26 10:58:26,647] ({pool-2-thread-6} IPythonInterpreter.java[launchIPythonKernel]:290) - IPython Kernel is Running
 INFO [2019-11-26 10:58:26,649] ({pool-2-thread-6} Py4JUtils.java[createGatewayServer]:44) - Launching GatewayServer at 127.0.0.1:35131
 INFO [2019-11-26 10:58:28,230] ({pool-2-thread-6} PySparkInterpreter.java[open]:130) - IPython is available, Use IPySparkInterpreter to replace PySparkInterpreter
 INFO [2019-11-26 10:58:28,366] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_640386539
 INFO [2019-11-26 10:58:33,617] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20191126-101625_1939198952 started by scheduler interpreter_640386539
 INFO [2019-11-26 10:58:34,038] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20191126-101625_1939198952 finished by scheduler interpreter_640386539
 INFO [2019-11-26 10:58:39,894] ({Thread-1} Logging.scala[logInfo]:54) - Invoking stop() from shutdown hook
 INFO [2019-11-26 10:58:39,930] ({Thread-1} AbstractConnector.java[doStop]:318) - Stopped Spark@69be06a9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-11-26 10:58:39,939] ({Thread-1} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://b77469278276:4040
 INFO [2019-11-26 10:58:39,972] ({Thread-1} Logging.scala[logInfo]:54) - Shutting down all executors
 INFO [2019-11-26 10:58:39,989] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Asking each executor to shut down
 INFO [2019-11-26 10:58:40,065] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2019-11-26 10:58:40,096] ({Thread-1} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2019-11-26 10:58:40,099] ({Thread-1} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2019-11-26 10:58:40,127] ({Thread-1} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2019-11-26 10:58:40,133] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2019-11-26 10:58:40,155] ({Thread-1} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2019-11-26 10:58:40,161] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2019-11-26 10:58:40,165] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-729b2d16-c656-4889-8b93-413b613d90b9
 INFO [2019-11-26 10:58:40,171] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-729b2d16-c656-4889-8b93-413b613d90b9/pyspark-07ac5357-4a49-46b5-90b6-16f938f51f29
 INFO [2019-11-26 10:58:40,178] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-8a2b3600-d36b-4652-9987-c7fdf9a703ed
